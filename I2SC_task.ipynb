{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhara\\Desktop\\Python\\I2SC_task\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define column names based on LIAR dataset structure\n",
    "columns = [\n",
    "    \"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"job\", \n",
    "    \"state\", \"party\", \"barely_true_counts\", \"false_counts\", \n",
    "    \"half_true_counts\", \"mostly_true_counts\", \"pants_on_fire_counts\", \"context\"\n",
    "]\n",
    "\n",
    "# Load the dataset\n",
    "\n",
    "df = pd.read_csv('train.tsv', sep='\\t', header=None, names=columns)\n",
    "\n",
    "# Keep only relevant columns\n",
    "df = df[[\"statement\", \"label\", \"context\", \"speaker\",'subject']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bhara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords (only needed once)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Define text cleaning function\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()  # Convert to lowercase\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "\n",
    "    else:\n",
    "        text = ''\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Preprocess only text-based columns\n",
    "text_columns = ['statement', 'context', 'subject','speaker'] \n",
    "for column in text_columns:\n",
    "    df[column] = df[column].astype(str).apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessed_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhara\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statement: since republicans took 2010 election graduation rate wisconsin gone 86 percent 88 percent black graduation rate gone 60 percent 65 percent latino graduation rate gone 65 percent 71 percent\n",
      "Label: half-true\n",
      "Context: nan\n",
      "speaker dalekooyenga\n",
      "BM25 Score: 123.0457\n",
      "--------------------------------------------------------------------------------\n",
      "Statement: says milwaukee blacks 55 percent male unemployment 60 percent truancy 50 percent graduation rate worst reading scores lead infant mortality\n",
      "Label: half-true\n",
      "Context: remarks\n",
      "speaker davidclarkejr\n",
      "BM25 Score: 43.5969\n",
      "--------------------------------------------------------------------------------\n",
      "Statement: rate uninsured americans 88 percent\n",
      "Label: half-true\n",
      "Context: medium post\n",
      "speaker barackobama\n",
      "BM25 Score: 42.6420\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Load preprocessed train data\n",
    "train_df = pd.read_csv(\"preprocessed_train.csv\")\n",
    "\n",
    "# Ensure 'statement' column is treated as text\n",
    "train_df[\"statement\"] = train_df[\"statement\"].astype(str)\n",
    "\n",
    "# Tokenize the statements\n",
    "\n",
    "tokenized_statements = [word_tokenize(statement) for statement in train_df[\"statement\"]]\n",
    "\n",
    "# Initialize BM25 Index\n",
    "bm25 = BM25Okapi(tokenized_statements)\n",
    "\n",
    "# Function to retrieve top-k similar claims\n",
    "def retrieve_claim(query, top_k=3):\n",
    "    query_tokens = word_tokenize(query.lower())  # Tokenize the query\n",
    "    scores = bm25.get_scores(query_tokens)  # Get BM25 scores for all claims\n",
    "    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]  # Get top-k matches\n",
    "    \n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        results.append({\n",
    "            \"statement\": train_df.iloc[idx][\"statement\"],\n",
    "            \"label\": train_df.iloc[idx][\"label\"],\n",
    "            \"context\": train_df.iloc[idx][\"context\"],\n",
    "            \"speaker\": train_df.iloc[idx][\"speaker\"],\n",
    "            \"score\": scores[idx]  # BM25 relevance score\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example Query\n",
    "query = \"Since Republicans took over after the 2010 election, the graduation rate in Wisconsin has gone from 86 percent to 88 percent. The black graduation rate has gone from 60 percent to 65 percent. The Latino graduation rate has gone from 65 percent to 71 percent.\"\n",
    "\n",
    "retrieved_claims = retrieve_claim(query)\n",
    "\n",
    "# Print Results\n",
    "for claim in retrieved_claims:\n",
    "    print(f\"Statement: {claim['statement']}\")\n",
    "    print(f\"Label: {claim['label']}\")\n",
    "    print(f\"Context: {claim['context']}\")\n",
    "    print(f\"speaker {claim['speaker']}\")\n",
    "    print(f\"BM25 Score: {claim['score']:.4f}\")\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you are referring to a claim by dalekooyenga, it is categorically False.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "\n",
    "def generate_fact_checking_response(query):\n",
    "    # Retrieve top claim (replace with your actual claim retrieval logic)\n",
    "    retrieved_claims = retrieve_claim(query, top_k=1)\n",
    "\n",
    "    if not retrieved_claims:\n",
    "        return \"I'm sorry, I couldn't find relevant information to fact-check this statement.\"\n",
    "\n",
    "    claim = retrieved_claims[0][\"statement\"]\n",
    "    label = retrieved_claims[0][\"label\"]\n",
    "    context = retrieved_claims[0][\"context\"]\n",
    "    speaker = retrieved_claims[0][\"speaker\"]\n",
    "\n",
    "    # Construct the prompt for the LLM\n",
    "    # Using a system role can help guide the model's behavior\n",
    "    system_prompt = \"\"\"\n",
    "    You are a fact-checking assistant. Your task is to determine if a provided claim is True or False, based strictly on the provided claim, label, context, and speaker.\n",
    "    Provide a direct, brief response in the format: \"If you are referring to a claim by [speaker], it is categorically [True/False].\"\n",
    "    Do not use external knowledge. Focus only on the provided information.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "Claim: \"{claim}\"\n",
    "Label: \"{label}\"\n",
    "Context: \"{context}\"\n",
    "Speaker: \"{speaker}\"\n",
    "Query: \"{query}\"\n",
    "\n",
    "Task: Based strictly on the provided information (Claim, Label, Context, Speaker), determine whether the claim is \"True\" or \"False.\" Provide a direct response in the following format:\n",
    "\n",
    "\"If you are referring to a claim by [speaker], it is categorically [True/False].\"\n",
    "\n",
    "Ensure the response is clear, brief, and focuses only on the provided information.\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "            messages=messages,\n",
    "            max_tokens= 200, # Adjust max_tokens as needed\n",
    "             temperature=0.1, # Keep temperature low for factual responses\n",
    "        )\n",
    "        # Extract the content from the completion object\n",
    "        return completion.choices[0].message.content.strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return \"An error occurred while processing the request.\"\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "query = \"Is the claim that the graduation rate in Wisconsin has improved since Republicans took over true?\"\n",
    "response = generate_fact_checking_response(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] query\n",
      "ipykernel_launcher.py: error: the following arguments are required: query\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhara\\Desktop\\Python\\I2SC_task\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set up command-line argument parsing\n",
    "    parser = argparse.ArgumentParser(description=\"Fact-checking question answering system.\")\n",
    "    parser.add_argument(\"query\", type=str, help=\"The query/question you want to verify.\")\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Generate the fact-checking response for the provided query\n",
    "    response = generate_fact_checking_response(args.query)\n",
    "    \n",
    "    # Output the response\n",
    "    print(\"System response:\", response)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhara\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
